# Primer Parcial - IA para la Econom√≠a 2025-2
**Universidad de los Andes - Facultad de Econom√≠a**

## üìã Informaci√≥n del Proyecto

Este repositorio contiene el desarrollo del primer parcial de la materia "IA para la Econom√≠a", enfocado en la aplicaci√≥n de algoritmos de Machine Learning cl√°sico para resolver problemas econ√≥micos utilizando el dataset de consumo de alcohol estudiantil.

### üéØ Objetivos
- Aplicar algoritmos de aprendizaje supervisado y no supervisado
- Implementar modelos predictivos para an√°lisis econ√≥mico
- Desarrollar habilidades en procesamiento y an√°lisis de datos
- Crear un pipeline completo desde la carga de datos hasta la evaluaci√≥n de modelos

## üìä Dataset

**Fuente**: scikit-learn/student-alcohol-consumption  
**Dimensiones**: 1,044 registros √ó 33 caracter√≠sticas  
**Variable objetivo**: G3 (calificaci√≥n final del estudiante)

### Variables principales:
- **Demogr√°ficas**: school, sex, age, address, famsize
- **Educativas**: Medu, Fedu, studytime, failures, schoolsup
- **Sociales**: activities, romantic, goout, Dalc, Walc
- **Acad√©micas**: G1, G2, G3 (calificaciones de per√≠odos)

## üõ†Ô∏è Tecnolog√≠as Utilizadas

```python
# Librer√≠as principales
pandas                 # Manipulaci√≥n de datos
numpy                  # Operaciones num√©ricas
scikit-learn          # Algoritmos de ML
matplotlib & seaborn   # Visualizaci√≥n
xgboost               # Algoritmos de ensamble
```

## üî¨ Metodolog√≠a

### 1. Exploraci√≥n y Preprocesamiento
- **Carga del dataset** desde Hugging Face datasets
- **An√°lisis exploratorio** de distribuciones y correlaciones
- **Limpieza de datos** eliminando duplicados basado en caracter√≠sticas clave
- **Normalizaci√≥n** de variables num√©ricas usando StandardScaler
- **Codificaci√≥n** de variables categ√≥ricas con LabelEncoder

### 2. Algoritmos Implementados

#### Aprendizaje Supervisado
- **Regresi√≥n Log√≠stica**: Modelo lineal con regularizaci√≥n
- **K-Nearest Neighbors (KNN)**: Clasificaci√≥n basada en distancia
- **Support Vector Machine (SVM)**: Clasificaci√≥n con kernels
- **√Årboles de Decisi√≥n**: Modelos interpretables
- **Random Forest**: Ensamble de √°rboles
- **XGBoost**: Gradient boosting optimizado

#### Aprendizaje No Supervisado
- **K-Means Clustering**: Segmentaci√≥n de estudiantes
- **PCA**: Reducci√≥n de dimensionalidad
- **An√°lisis de Silhouette**: Evaluaci√≥n de clusters

### 3. Evaluaci√≥n de Modelos
- **Validaci√≥n cruzada** con StratifiedKFold
- **M√©tricas de clasificaci√≥n**: accuracy, precision, recall, F1-score
- **Matrices de confusi√≥n** y curvas ROC
- **Comparaci√≥n de rendimiento** entre algoritmos

## üìÅ Estructura del Repositorio

```
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Copia_de_Parcial1AI.ipynb    # Notebook principal
‚îú‚îÄ‚îÄ data/                             # Datos procesados
‚îú‚îÄ‚îÄ models/                           # Modelos entrenados
‚îú‚îÄ‚îÄ results/                          # Resultados y visualizaciones
‚îú‚îÄ‚îÄ docs/                            # Documentaci√≥n adicional
‚îî‚îÄ‚îÄ README.md                        # Este archivo
```

## üöÄ Instrucciones de Uso

### Prerrequisitos
```bash
pip install pandas numpy scikit-learn matplotlib seaborn xgboost datasets
```

### Ejecuci√≥n
1. Clonar el repositorio
2. Abrir el notebook en Google Colab o Jupyter
3. Ejecutar las celdas secuencialmente
4. Los resultados se guardar√°n autom√°ticamente

## üìà Resultados Principales

### Preprocesamiento
- **Datos originales**: 1,044 registros
- **Despu√©s de limpieza**: 662 registros √∫nicos
- **Duplicados eliminados**: 382 registros

### Variables Procesadas
- **Num√©ricas estandarizadas**: 15 variables (age, Medu, Fedu, etc.)
- **Categ√≥ricas codificadas**: 13 variables (school, sex, address, etc.)

### Modelos Entrenados
- Implementaci√≥n exitosa de 6 algoritmos supervisados
- Clustering con K-Means para segmentaci√≥n
- Reducci√≥n dimensional con PCA
- Evaluaci√≥n comparativa de rendimiento

## Curva ROC
Se evidencia que todos los modelos tienen un buen rendimiento, sin embargo, KNN con tiene el peor rendimiento de los tres modelos, ya que, detecta bien a los estudiantes que aprueban/reprueban, pero comete m√°s falsos positivos. En cambio,  sobresale Randomforest, siendo este modelo el de mejor rendimiento de los tres, lo que implica que distingue con mucha precisi√≥n entre aprobar y reprobar.

## Modelos
Los tres modelos muestran buenos resultados : las accuracies son superiores a 0.84. 
- KNN: El recall es muy alto lo que significa que el modelo detecta casi todos los casos positivos pero tiene menor precisi√≥n y AUC, lo que indica que genera m√°s FP 
- XGBoost: El modelo es confiable y robusto porque su AUC es muy alto lo que demuestra una excelente capacidad de distinguir entre clases. El recall y la precisi√≥n presentan un buen equilibrio. 
- RandomForest: El modelo minimiza los FP y discrimina con mayor eficiencia entre las clases. Tiene la mejor precisi√≥n y el mejor AUC 

## Validacion Cruzada
Random Forest alcanza los valores de F1 m√°s altos en la validaci√≥n cruzada y muestra una gran consistencia entre los distintos folds. KNN, en cambio, presenta el peor desempe√±o: sus F1-scores son claramente m√°s bajos y con mayor variabilidad, lo que indica que depende m√°s de la partici√≥n de datos que le toque. Por su parte, XGBoost tambi√©n exhibe un rendimiento muy competitivo, con resultados cercanos a los de Random Forest, aunque con una ligera mayor dispersi√≥n en los folds.


## üí° Aplicaciones Econ√≥micas

Este proyecto demuestra c√≥mo los algoritmos de ML pueden aplicarse a:
- **Predicci√≥n de rendimiento acad√©mico** como proxy de capital humano
- **Segmentaci√≥n de poblaciones** para pol√≠ticas educativas focalizadas
- **Identificaci√≥n de factores** socioecon√≥micos relevantes en educaci√≥n
- **Optimizaci√≥n de recursos** educativos basada en perfiles estudiantiles

## üë• Contribuidores

- **Equipo de desarrollo**: Adrian Montenegro Zamora, Daniel Esteban Gonzalez Vergara, Godwin Zuluaga Garcia, Jade Manon Nicolas, Juan Pablo Camacho Pe√±a, Luis Alejandro Suarez Arevalo, Maria Alejandra Velasquez Chauta.
- **Profesor**: Camilo Vega Barbosa
- **Profesor complementario**: Daniel Aguirre

## üìö Referencias

- Cortez, P. & Silva, A. (2008). Using Data Mining to Predict Secondary School Student Performance
- Scikit-learn documentation
- XGBoost documentation
- Curso "IA para la Econom√≠a" - Universidad de los Andes

## üìÑ Licencia

Este proyecto se desarrolla con fines acad√©micos para la Universidad de los Andes.

---

**Fecha de entrega**: Semana 5 - Segundo semestre 2025  
**Evaluaci√≥n**: 50% presentaci√≥n + 50% entregable en GitHub

> **Nota**: Este proyecto cumple con las pol√≠ticas de integridad acad√©mica de la Universidad de los Andes. Todo el c√≥digo y an√°lisis es original del equipo, citando apropiadamente las fuentes externas utilizadas.
